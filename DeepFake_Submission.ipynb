{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFake Submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Method** **1**\n",
        "This submission gave a score of 0.69871 in Private Leaderboard. However the number of vidoes used in the training from fake is only 6% of total provided videos. Similarly the number of videos of videos for real used are also less. This had to be done due to constriants of memory space and time.\n",
        "Hence the lower score. Also this file has been trained across three platforms, a part of it in Google Colab, Jupyter and Kaggle (due to memory space constrains)."
      ],
      "metadata": {
        "id": "50J0xHxZrRgi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K31RTHU6xjN"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements here include:\n",
        "1. numpy\n",
        "2. pandas\n",
        "3. tensorflow\n",
        "4. keras>=2.2.0\n",
        "5. keras_applications >= 1.0.7\n",
        "6. opencv-python>=4.1.0\n",
        "7. mtcnn>=0.1.0\n",
        "8. h5py\n",
        "9. efficientnet\n",
        "10. split_folders"
      ],
      "metadata": {
        "id": "8uHC80Y168Ik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting our Google Drive from where we'll access the competition Dataset and subsequently store preperations"
      ],
      "metadata": {
        "id": "dve7k2ES76Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "dAYwg3yJ67NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next task is to extract trainable images from the video dataset provided. First we have selected the 'Celeb-real' dataset consisting of real videos of Celebs"
      ],
      "metadata": {
        "id": "CxRgLAvW-04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "base_path = '/content/deep-fake-dataset/Celeb-real'\n",
        "def get_filename_only(file_path):\n",
        "    file_basename = os.path.basename(file_path)\n",
        "    filename_only = file_basename.split('.')[0]\n",
        "    return filename_only\n"
      ],
      "metadata": {
        "id": "7sNcHryk-vnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a path to store the names of files. Since here the names of files are numberical from 0.mp4 to 481.mp4"
      ],
      "metadata": {
        "id": "9yIzRfl9_3WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = []\n",
        "for i in range(0,482):\n",
        "  file_path.append(os.path.join(base_path, str(i) + '.mp4'))\n",
        "\n",
        "print(len(file_path)) "
      ],
      "metadata": {
        "id": "JvXfulnh_8MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowloading the required libraries to process the videos"
      ],
      "metadata": {
        "id": "gqJuUxhPFFyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "import sys, os.path\n",
        "import json\n",
        "from keras import backend as K\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "BqwreFslFE8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating images from videos with a minimum frames of 15 for each. And then storing them in a new location for each image"
      ],
      "metadata": {
        "id": "yxcijaTzAVdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "w9h-NE_09GY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cropping faces from images using MTCNN that read the images and crops the faces in it while storing it in a location called faces for each folder\n",
        "\n",
        "P.S: The sizes of the images are not even and we will handle this later on while training the images"
      ],
      "metadata": {
        "id": "m4W2TRD9DUou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "gOnYejjI9pGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating the same process again for:\n",
        "1. Celeb-Youtube Fake"
      ],
      "metadata": {
        "id": "p81d5cm3Ff_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/deep-fake-dataset/Celeb-Youtube-fake'\n",
        "\n",
        "file_path = []\n",
        "for i in range(0,5299):\n",
        "  file_path.append(os.path.join(base_path, str(i) + '.mp4'))\n",
        "\n",
        "print(len(file_path)) "
      ],
      "metadata": {
        "id": "sH_zSO5eFoRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "btl30mMiHKXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "    print('Processing Directory: ' + tmp_path)\n",
        "    frame_images = [x for x in os.listdir(tmp_path) if os.path.isfile(os.path.join(tmp_path, x))]\n",
        "    faces_path = os.path.join(tmp_path, 'faces')\n",
        "    print('Creating Directory: ' + faces_path)\n",
        "    os.makedirs(faces_path, exist_ok=True)\n",
        "    print('Cropping Faces from Images...')\n",
        "\n",
        "    for frame in frame_images:\n",
        "        print('Processing ', frame)\n",
        "        detector = MTCNN()\n",
        "        image = cv2.imread(os.path.join(tmp_path, frame))\n",
        "        results = detector.detect_faces(image)\n",
        "        print('Face Detected: ', len(results))\n",
        "        count = 0\n",
        "        \n",
        "        for result in results:\n",
        "            bounding_box = result['box']\n",
        "            print(bounding_box)\n",
        "            confidence = result['confidence']\n",
        "            print(confidence)\n",
        "            if len(results) < 2 or confidence > 0.95:\n",
        "                margin_x = bounding_box[2] * 0.3  # 30% as the margin\n",
        "                margin_y = bounding_box[3] * 0.3  # 30% as the margin\n",
        "                x1 = int(bounding_box[0] - margin_x)\n",
        "                if x1 < 0:\n",
        "                    x1 = 0\n",
        "                x2 = int(bounding_box[0] + bounding_box[2] + margin_x)\n",
        "                if x2 > image.shape[1]:\n",
        "                    x2 = image.shape[1]\n",
        "                y1 = int(bounding_box[1] - margin_y)\n",
        "                if y1 < 0:\n",
        "                    y1 = 0\n",
        "                y2 = int(bounding_box[1] + bounding_box[3] + margin_y)\n",
        "                if y2 > image.shape[0]:\n",
        "                    y2 = image.shape[0]\n",
        "                print(x1, y1, x2, y2)\n",
        "                \n",
        "                crop_image = image[y1:y2, x1:x2]\n",
        "                new_filename = '{}-{:02d}.png'.format(os.path.join(faces_path, get_filename_only(frame)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, cv2.cvtColor(crop_image, cv2.COLOR_RGB2BGR))\n",
        "                print(count)\n",
        "            else:\n",
        "                print('Skipped a face..')"
      ],
      "metadata": {
        "id": "jRO29aUnHN3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Youtube-Real"
      ],
      "metadata": {
        "id": "B3a7cq6xIj_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/deep-fake-dataset/Youtube-real'\n",
        "\n",
        "file_path = []\n",
        "for i in range(0,230):\n",
        "  file_path.append(os.path.join(base_path, str(i) + '.mp4'))\n",
        "\n",
        "print(len(file_path)) "
      ],
      "metadata": {
        "id": "bzckhkkdImDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "TnH9HcmlJDbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "    print('Processing Directory: ' + tmp_path)\n",
        "    frame_images = [x for x in os.listdir(tmp_path) if os.path.isfile(os.path.join(tmp_path, x))]\n",
        "    faces_path = os.path.join(tmp_path, 'faces')\n",
        "    print('Creating Directory: ' + faces_path)\n",
        "    os.makedirs(faces_path, exist_ok=True)\n",
        "    print('Cropping Faces from Images...')\n",
        "\n",
        "    for frame in frame_images:\n",
        "        print('Processing ', frame)\n",
        "        detector = MTCNN()\n",
        "        image = cv2.imread(os.path.join(tmp_path, frame))\n",
        "        results = detector.detect_faces(image)\n",
        "        print('Face Detected: ', len(results))\n",
        "        count = 0\n",
        "        \n",
        "        for result in results:\n",
        "            bounding_box = result['box']\n",
        "            print(bounding_box)\n",
        "            confidence = result['confidence']\n",
        "            print(confidence)\n",
        "            if len(results) < 2 or confidence > 0.95:\n",
        "                margin_x = bounding_box[2] * 0.3  # 30% as the margin\n",
        "                margin_y = bounding_box[3] * 0.3  # 30% as the margin\n",
        "                x1 = int(bounding_box[0] - margin_x)\n",
        "                if x1 < 0:\n",
        "                    x1 = 0\n",
        "                x2 = int(bounding_box[0] + bounding_box[2] + margin_x)\n",
        "                if x2 > image.shape[1]:\n",
        "                    x2 = image.shape[1]\n",
        "                y1 = int(bounding_box[1] - margin_y)\n",
        "                if y1 < 0:\n",
        "                    y1 = 0\n",
        "                y2 = int(bounding_box[1] + bounding_box[3] + margin_y)\n",
        "                if y2 > image.shape[0]:\n",
        "                    y2 = image.shape[0]\n",
        "                print(x1, y1, x2, y2)\n",
        "                \n",
        "                crop_image = image[y1:y2, x1:x2]\n",
        "                new_filename = '{}-{:02d}.png'.format(os.path.join(faces_path, get_filename_only(frame)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, cv2.cvtColor(crop_image, cv2.COLOR_RGB2BGR))\n",
        "                print(count)\n",
        "            else:\n",
        "                print('Skipped a face..')"
      ],
      "metadata": {
        "id": "qquykgoEJq84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having converted videos to images with cropped faces we need to store all the images in seperate folder for 'Real'(combining Celeb-real and YouTube-real) and 'Fake' (Celeb-YouTube-fake)"
      ],
      "metadata": {
        "id": "jJCMqFt4LixF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_path = 'content/FakeImages'\n",
        "base_path = '/content/deep-fake-dataset/Celeb-Youtube-fake'\n",
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    \n",
        "    tmp_path = os.path.join(os.path.join(base_path, get_filename_only(filename)), 'faces')\n",
        "    print(tmp_path)\n",
        "    if os.path.exists(tmp_path):\n",
        "      print('Copying to :' + fake_path)\n",
        "      copy_tree(tmp_path, fake_path)\n",
        "        "
      ],
      "metadata": {
        "id": "P688HXzrM0-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Here we will have to change the name of YouTube real images so that we can combine YouTube-real and Celeb-real"
      ],
      "metadata": {
        "id": "WwIy2mITQZ5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/deep-fake-dataset/Youtube-real'\n",
        "for count, filename in enumerate(os.listdir(folder)):\n",
        "        dst = f\"Hostel {str(count)}.jpg\"\n",
        "        src =f\"{folder}/{filename}\"  # foldername/filename, if .py file is outside folder\n",
        "        dst =f\"{folder}/{dst}\"\n",
        "         \n",
        "        # rename() function will\n",
        "        # rename all the files\n",
        "        os.rename(src, dst)"
      ],
      "metadata": {
        "id": "eeKglpY_Pcmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_path = 'content/RealImages'\n",
        "base_path = '/content/deep-fake-dataset/Youtube-real'\n",
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    \n",
        "    tmp_path = os.path.join(os.path.join(base_path, get_filename_only(filename)), 'faces')\n",
        "    print(tmp_path)\n",
        "    if os.path.exists(tmp_path):\n",
        "      print('Copying to :' + real_path)\n",
        "      copy_tree(tmp_path, real_path)"
      ],
      "metadata": {
        "id": "XX-uOXSUSHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_path = 'content/RealImages'\n",
        "base_path = '/content/deep-fake-dataset/Celeb-real'\n",
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    \n",
        "    tmp_path = os.path.join(os.path.join(base_path, get_filename_only(filename)), 'faces')\n",
        "    print(tmp_path)\n",
        "    if os.path.exists(tmp_path):\n",
        "      print('Copying to :' + real_path)\n",
        "      copy_tree(tmp_path, real_path)"
      ],
      "metadata": {
        "id": "v8pv9JZ9Pboi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will store the list of all the Real and Fake Images"
      ],
      "metadata": {
        "id": "f2PeY6TKSp1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "tmp_fake_path = 'content/FakeImages'\n",
        "all_fake_faces = [f for f in os.listdir(tmp_fake_path) if os.path.isfile(os.path.join(tmp_fake_path, f))]\n",
        "print('Total Number of Fake faces: ', len(all_fake_faces))"
      ],
      "metadata": {
        "id": "W7ODvPyEUeJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_real_path = 'content/RealImages'\n",
        "all_real_faces = [f for f in os.listdir(tmp_real_path) if os.path.isfile(os.path.join(tmp_real_path, f))]\n",
        "print('Total Number of Real faces: ', len(all_real_faces))"
      ],
      "metadata": {
        "id": "WFX3lPc0UptB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting 6000 frames each of Real and Fake Images (Since we need to keep the count of real and fake images equal)"
      ],
      "metadata": {
        "id": "WMuqAmjPU4YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "fake_faces = np.random.choice(all_fake_faces, 6000, replace=False)\n",
        "for fname in fake_faces:\n",
        "    src = os.path.join(tmp_fake_path, fname)\n",
        "print('Total Number of Fake faces: ', len(fake_faces))"
      ],
      "metadata": {
        "id": "DNNjuLl5WbPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_faces = np.random.choice(all_real_faces, 6000, replace=False)\n",
        "for fname in real_faces:\n",
        "    src = os.path.join(tmp_fake_path, fname)\n",
        "print('Total Number of Real faces: ', len(real_faces))"
      ],
      "metadata": {
        "id": "Wn973pC8W5A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next task will be to create a data and a target dataset. For the same I employed two methods:\n",
        "1. Created X and Y by appending both real and fake images (converted to array). And then subsequently spliting them into train and test with a random state.\n",
        "2. The second approach will be to avoid overfitting we will take equal number of Real images and fake images in train dataset. And do the same for test as well. In this also we can try two approches: \n",
        " a) Keeping the random state of both the test and train split same\n",
        " b) Keeping the random state of both the test and train split different\n",
        "\n",
        "(P.S. The first approch gave better results)"
      ],
      "metadata": {
        "id": "tafvq-LlXLhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analysing the sizes of the images (they were different), converted all the images to size (128, 128, 3) and then convert to array and flatten to store."
      ],
      "metadata": {
        "id": "vchq2dM1cLKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def img_to_array(img, data_format='channels_last', dtype='float32'):\n",
        "    \"\"\"Converts a PIL Image instance to a Numpy array.\n",
        "    # Arguments\n",
        "        img: PIL Image instance.\n",
        "        data_format: Image data format,\n",
        "            either \"channels_first\" or \"channels_last\".\n",
        "        dtype: Dtype to use for the returned array.\n",
        "    # Returns\n",
        "        A 3D Numpy array.\n",
        "    # Raises\n",
        "        ValueError: if invalid `img` or `data_format` is passed.\n",
        "    \"\"\"\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format: %s' % data_format)\n",
        "    # Numpy array x has format (height, width, channel)\n",
        "    # or (channel, height, width)\n",
        "    # but original PIL image has format (width, height, channel)\n",
        "    x = np.asarray(img, dtype=dtype)\n",
        "    if len(x.shape) == 3:\n",
        "        if data_format == 'channels_first':\n",
        "            x = x.transpose(2, 0, 1)\n",
        "    elif len(x.shape) == 2:\n",
        "        if data_format == 'channels_first':\n",
        "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
        "        else:\n",
        "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
        "    else:\n",
        "        raise ValueError('Unsupported image shape: %s' % (x.shape,))\n",
        "    return x"
      ],
      "metadata": {
        "id": "qyyX6Xn_eooh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "data_dir = 'content/RealImages'\n",
        "\n",
        "for img in real_faces:\n",
        "    image = cv2.imread(data_dir+'/'+img, 1)\n",
        "    bigger = cv2.resize(image, (128, 128))\n",
        "    bigger = img_to_array(bigger).flatten() / 255.0\n",
        "    #X.append(img_to_array(load_img(data_dir+'/'+img)).flatten() / 255.0)\n",
        "    X.append(bigger)\n",
        "    Y.append(1)\n"
      ],
      "metadata": {
        "id": "zl2sXnjWbWu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'content/FakeImages'\n",
        "\n",
        "for img in fake_faces:\n",
        "    image = cv2.imread(data_dir+'/'+img, 1)\n",
        "    if image is not None:\n",
        "        bigger = cv2.resize(image, (128, 128))\n",
        "        bigger = img_to_array(bigger).flatten() / 255.0\n",
        "        #X.append(img_to_array(load_img(data_dir+'/'+img)).flatten() / 255.0)\n",
        "        X.append(bigger)\n",
        "        Y.append(0)"
      ],
      "metadata": {
        "id": "evkPr3fZesKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#deleting unrequired space to gain some space\n",
        "image = None\n",
        "bigger= None\n",
        "random_faces = None\n",
        "data_dir = None\n",
        "src = None\n",
        "tmp_real_path = None\n",
        "all_real_faces = None\n",
        "all_fake_faces = None"
      ],
      "metadata": {
        "id": "Jb76BSSwfTro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "Y_val_org = Y\n",
        "#Normalization\n",
        "X = np.array(X)\n",
        "Y = to_categorical(Y, 2)\n",
        "\n",
        "#from numpy import savetxt\n",
        "\n",
        "#Reshape\n",
        "X = X.reshape(-1, 128, 128, 3)\n",
        "\n",
        "\n",
        "\n",
        "#Train-Test split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=60)"
      ],
      "metadata": {
        "id": "V5GYpT4tfgmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "F7CX8WYIgE_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128,128,3)\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "googleNet_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "googleNet_model.trainable = True\n",
        "model = Sequential()\n",
        "model.add(googleNet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BQdb9h59gID9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Currently not used\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               min_delta=0,\n",
        "                               patience=2,\n",
        "                               verbose=0, mode='auto')\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 100\n",
        "history = model.fit(X_train, Y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (X_val, Y_val), verbose = 1)"
      ],
      "metadata": {
        "id": "zAMgyKFHgNJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the result"
      ],
      "metadata": {
        "id": "cgtb8XusgRxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n",
        "t = f.suptitle('Pre-trained InceptionResNetV2 Transfer Learn with Fine-Tuning & Image Augmentation Performance ', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,EPOCHS+1))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch #')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch #')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "Bxn6E6-KgQ-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output confusion matrix\n",
        "def print_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print('True positive = ', cm[0][0])\n",
        "    print('False positive = ', cm[0][1])\n",
        "    print('False negative = ', cm[1][0])\n",
        "    print('True negative = ', cm[1][1])\n",
        "    print('\\n')\n",
        "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "    sn.set(font_scale=1.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "    plt.ylabel('Actual label', size = 20)\n",
        "    plt.xlabel('Predicted label', size = 20)\n",
        "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.ylim([2, 0])\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "tDJqb63qg0xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the prediction ito 0 and 1 which is our required target"
      ],
      "metadata": {
        "id": "92a5t7rlhAXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_x=model.predict(X) \n",
        "classes_x=np.argmax(predict_x,axis=1)"
      ],
      "metadata": {
        "id": "tVdi74MZg-S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print_confusion_matrix(Y_val_org, classes_x)"
      ],
      "metadata": {
        "id": "VnQxh85uiDJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have our model prepared"
      ],
      "metadata": {
        "id": "Qrw29_E6iFfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "lG9LhV30iJfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we shall use this model to predict if the test videos are real or deepfake"
      ],
      "metadata": {
        "id": "CLgMDptFiMjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here to list down the names of test images we used a different approch as the names of files in test deepfake-dataset weren't uniform"
      ],
      "metadata": {
        "id": "57TSVssplsnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "\n",
        "tmp_test_path = '/content/content/deep-fake-dataset/test'\n",
        "file_path = [f for f in os.listdir(tmp_test_path) if os.path.isfile(os.path.join(tmp_test_path, f))]\n",
        "print('Total Number of Test files: ', len(file_path))"
      ],
      "metadata": {
        "id": "x5WOzazojWY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeated the same process again to convert first videos to frames and the cropping faces from the frames"
      ],
      "metadata": {
        "id": "dvNmR1mZmh5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "wF8xUi7plCUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in file_path:\n",
        "    print(filename)\n",
        "    if (filename.endswith(\".mp4\")):\n",
        "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "        print('Creating Directory: ' + tmp_path)\n",
        "        os.makedirs(tmp_path, exist_ok=True)\n",
        "        print('Converting Video to Images...')\n",
        "        count = 0\n",
        "        video_file = os.path.join(base_path, filename)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_rate = cap.get(5) #frame rate\n",
        "        while(cap.isOpened()):\n",
        "            frame_id = cap.get(1) #current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if (ret != True):\n",
        "                break\n",
        "            if (frame_id % math.floor(frame_rate) == 0):\n",
        "                print('Original Dimensions: ', frame.shape)\n",
        "                if frame.shape[1] < 300:\n",
        "                    scale_ratio = 2\n",
        "                elif frame.shape[1] > 1900:\n",
        "                    scale_ratio = 0.33\n",
        "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
        "                    scale_ratio = 0.5\n",
        "                else:\n",
        "                    scale_ratio = 1\n",
        "                print('Scale Ratio: ', scale_ratio)\n",
        "\n",
        "                width = int(frame.shape[1] * scale_ratio)\n",
        "                height = int(frame.shape[0] * scale_ratio)\n",
        "                dim = (width, height)\n",
        "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "                print('Resized Dimensions: ', new_frame.shape)\n",
        "\n",
        "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
        "                count = count + 1\n",
        "                cv2.imwrite(new_filename, new_frame)\n",
        "        cap.release()\n",
        "        print(\"Done!\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "iI_j2ozalNum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a dictionary to store our results for each of the test videos"
      ],
      "metadata": {
        "id": "VJ-_wIvmn1cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "IW1P1jVUn002"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For applying the model to the test imges, we have employed the following methods:\n",
        "1. Iterated through each of files consisting of cropped faces in each folder for test videos\n",
        "2. Resized the images to (128, 128, 3) and convert to array\n",
        "3. Made prediction using our model\n",
        "4. Now for each video file name , we might have some images being labeled as 0 and a few 1, hence we will take the majority as the absolute prediction for the video file. For eg. if for a video file 11 images gave 0 while the other 2 images gave 1 then we will take 0 as the answer"
      ],
      "metadata": {
        "id": "eFvigBLBoFpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnt =0\n",
        "for filename in file_path:\n",
        "  \n",
        "  tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
        "  faces_path = os.path.join(tmp_path, 'faces')\n",
        "  frame_images = [x for x in os.listdir(faces_path) if os.path.isfile(os.path.join(faces_path, x))]\n",
        "  print(frame_images)\n",
        "  count_0 = 0\n",
        "  count_1 = 0\n",
        "\n",
        "\n",
        "  for frame in frame_images:\n",
        "    image = cv2.imread(faces_path+'/'+ frame, 1)\n",
        "    data = img_to_array(cv2.resize(image, (128, 128))).flatten() / 255.0\n",
        "    data = data.reshape(-1, 128, 128, 3)\n",
        "    predict_x=model1.predict(data) \n",
        "    classes_x=np.argmax(predict_x,axis=1)\n",
        "    \n",
        "    if (classes_x==0):\n",
        "      count_0 = count_0 + 1\n",
        "    if (classes_x==1):\n",
        "      count_1 = count_1 + 1\n",
        "    \n",
        "  cnt = cnt+1\n",
        "  print(\"count 1\", count_1, \"count 0\", count_0)\n",
        "  if (count_0>=count_1):\n",
        "    dict1[filename] = 0\n",
        "  if (count_1>count_0):\n",
        "    dict1[filename] = 1\n",
        "  \n",
        "  print(filename)\n",
        "  print(cnt)\n",
        "  print(dict1)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "Qc8pCWuUoCbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the file for submission we will upload the sample submission given and assign the predicted values"
      ],
      "metadata": {
        "id": "5_ot7Pc1qLCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "submit = pd.read_csv('sample_submission.csv')\n",
        "for i in range(518):\n",
        "  submit['label'][i] = dict1[submit['id'][i]]"
      ],
      "metadata": {
        "id": "PKz8slNyp_Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "y_dMJg6wrNne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}